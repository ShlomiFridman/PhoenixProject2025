# -*- coding: utf-8 -*-
"""phoenixproject2025_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15etxIQVNJB8syQAj_0bftT9qIyGDJHzD

github link: https://github.com/ShlomiFridman/PhoenixProject2025

# Install
"""

!pip install requests beautifulsoup4
!pip install requests beautifulsoup4 nltk
!pip install firebase

"""# Imports"""

import requests
import time
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from urllib.robotparser import RobotFileParser
from nltk.stem import PorterStemmer
import re
from firebase import firebase
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import ipywidgets as widgets
from IPython.display import display, HTML, Markdown, SVG
from collections import defaultdict
import pathlib
import textwrap
import google.generativeai as genai
from nltk.chat.util import Chat, reflections
import difflib
import numpy as np
import base64

"""# Util functions"""

def index_words(soup):
    index_res = {}
    words = re.findall(r'\w+', soup.get_text())

    for word in words:
        word = word.lower()

        if word in index_res:
            index_res[word] += 1
        else:
            index_res[word] = 1

    return index_res

def remove_stop_words(p_index):
    stop_words = {'a', 'an', 'the', 'and', 'or', 'in', 'on', 'at', 'to'}

    for stop_word in stop_words:
        if stop_word in p_index:
            del p_index[stop_word]

    return p_index

def apply_stemming(p_index):
    stemmer = PorterStemmer()
    stemmed_index = {}

    for word, count in p_index.items():
        stemmed_word = stemmer.stem(word)

        if stemmed_word in stemmed_index:
            stemmed_index[stemmed_word] += count
        else:
            stemmed_index[stemmed_word] = count

    return stemmed_index

"""# Firebase Service"""

class FirebaseService:

  def __init__(self, db_url = 'https://phoenixfinal-5a3f2-default-rtdb.europe-west1.firebasedatabase.app/'):
    self.FBconn = firebase.FirebaseApplication(db_url,None)

  def get_rev_index_from_DB(self):
    return self.FBconn.get('/Index/', None)

  def update_rev_index_in_db(self, index_p):
    self.FBconn.delete("/Index/", None)
    print("Cleared database before save")
    for k,v in index_p.items():
      self.FBconn.put("/Index/", k, v)
      print(f"update made for index={k} ({v['term']})")
    print("Updated given rev index in DB")

  def get_snippets(self):
      try:
          snippets = self.FBconn.get('/Snippets/', None)
          if not snippets:
              return {}
          return {base64.urlsafe_b64decode(k).decode(): v for k, v in snippets.items()}
      except Exception as e:
          print(f"Error fetching snippets: {e}")
          return {}

  def update_snippets_in_db(self, snippets_p):
      try:
          self.FBconn.delete("/Snippets/", None)
          print("Cleared database before save")
          for k, v in snippets_p.items():
              encoded_k = base64.urlsafe_b64encode(k.encode()).decode()
              self.FBconn.put("/Snippets/", encoded_k, v)
              print(f"Update made for url={k}")
          print("Updated snippets in DB")
      except Exception as e:
          print(f"Error updating snippets: {e}")



"""# Index Service"""

class IndexService:

  def __init__(self, index = None, firebaseService = None):
    self.default_index_words = [
        'SAAS',
        'PAAS',
        'IAAS',
        'FAAS',
        'Private',
        'Public',
        'Hybrid',
        'Service',
        'Platform',
        'Infrastructure',
        'Study',
        'Case',
        'Chatbot',
        'Engine',
        'Cloud',
        'Monitor',
        'Data',
        'Mainframe',
        'Performance',
        'Security',
        'SLA',
        'KPI',
        'SOA',
        'Information',
        'Kafka',
        'SQL',
        'Technology',
        'Database',
        'Docker',
        'Kubernetes',
        'RabbitMQ',
        'IBM',
        'Google',
        'Amazon',
        'AI',
        'Artificial',
        'Intelligence',
        'Mining',
        'vector',
        'DDoS',
        'Phishing',
        'Quantum',
        'Deep',
        'Algorithm',
        'NLP',
        'Neural',
        'regression',
        'Monte Carlo',
        'Preventive',
        'CMMS',
        'Twin',
        'Automation',
        'Workflow',
        'API',
        'REST',
        'Interactive',
        'Serverless',
        'NoSQL',
        'Schema',
        'DevOps',
        'Israel',
        'Storage',
        'Middleware',
        'Microservice',
        'Mobile',
        'Java',
        'Python',
        'Architecture',
        'Malware',
        'CAPTCHA',
    ]
    self.init_index_vals = index if index else self.default_index_words
    self.snippets = {}
    self.stemmer = PorterStemmer()
    self.firebaseService = firebaseService
    self.resetService()

  def process_soup(self, url, soup):
    if not soup:
        print("empty soup")
        return

    u_index = index_words(soup)
    u_index = remove_stop_words(u_index)
    u_index = apply_stemming(u_index)
    self.urls_index[url] = u_index

    for ind, ind_val in self.rev_index.items():
        if ind not in u_index:
            continue
        elif url in ind_val['DocIDs']:
            url_i = ind_val["DocIDs"].index(url)
            del ind_val["DocIDs"][url_i]
            del ind_val["DocIDs_cntrs"][url_i]

        # Initialize lists if they don't exist
        if "DocIDs" not in ind_val:
            ind_val['DocIDs'] = []
        if "DocIDs_cntrs" not in ind_val:
            ind_val['DocIDs_cntrs'] = []

        # Append to the lists
        ind_val['DocIDs'].append(url)
        ind_val['DocIDs_cntrs'].append(u_index[ind])

        # Create the snippet (first 23 words)
        snippet = " ".join(soup.get_text().split()[:23])  # Ensure you get the first 23 words from the text
        self.snippets[url] = snippet

    return u_index

  def get_reverse_index(self):
    return self.rev_index

  def get_url_index(self, url):
    return self.urls_index.get(url,{})

  def set_rev_index(self, newRevIndex):
    self.init_index_vals = [vals['term'] for ind,vals in newRevIndex.items()]
    self.rev_index = newRevIndex
    self.urls_index = {}

    for ind, vals in self.rev_index.items():
      if 'DocIDs' not in vals:
        vals['DocIDs'] = []
        vals['DocIDs_cntrs'] = []
      urls = vals['DocIDs']
      cntrs = vals['DocIDs_cntrs']
      for j in range(len(urls)):
        if urls[j] not in self.urls_index:
          self.urls_index[urls[j]] = {}
        self.urls_index[urls[j]][ind] = cntrs[j]
    # print("index updated")

  def get_index_of_word(self, w):
    stemmed_w = self.stemmer.stem(w)
    return self.rev_index.get(stemmed_w, None)

  def add_new_word(self, word):
    stemmedWord = self.stemmer.stem(word)
    if (stemmedWord in self.rev_index):
      return False
    self.init_index_vals.append(word)
    self.rev_index[stemmedWord] = {"term": word, "DocIDs": [], "DocIDs_cntrs": []}
    return True

  def remove_word(self, word):
    stemmedWord = self.stemmer.stem(word)
    if stemmedWord not in self.rev_index:
      return False
    self.init_index_vals.remove(self.rev_index[stemmedWord]['term'])
    del self.rev_index[stemmedWord]
    return True

  def remove_url(self, url):
    if url not in self.urls_index:
      return False
    for word,cntr in self.urls_index[url].items():
      if word not in self.rev_index:
        continue
      ind = self.rev_index[word]["DocIDs"].index(url)
      del self.rev_index[word]["DocIDs"][ind]
      del self.rev_index[word]["DocIDs_cntrs"][ind]
    del self.urls_index[url]
    return True

  def save_in_db(self):
    if self.firebaseService:
      self.firebaseService.update_rev_index_in_db(self.rev_index)
      self.firebaseService.update_snippets_in_db(self.snippets)
    else:
      print("IndexService does not have FirebaseService")
  def load_from_db(self):
    if self.firebaseService:
      db_index = self.firebaseService.get_rev_index_from_DB()
      if db_index:
        self.set_rev_index(db_index)
      db_snippets = self.firebaseService.get_snippets()
      if db_snippets:
        self.snippets = db_snippets
    else:
      print("IndexService does not have FirebaseService")

  def index_toString(self, minView=True):
    str = ''
    for ind,vals in self.rev_index.items():
      str += f"Index '{ind}'\n"
      str += f"\tTerm='{vals['term']}'\n"
      str += "\tDocIDs=\n"
      if not minView:
        for j in range(len(vals['DocIDs'])):
          str += f"\t\tURL No.{j}: {vals['DocIDs'][j]} - {vals['DocIDs_cntrs'][j]} times\n"
      else:
        str += f"\t\tTotal Urls: {len(vals['DocIDs'])}\n"
        str += f"\t\tTotal Occurrences: {sum(vals['DocIDs_cntrs'])}\n"
    return str

  def resetService(self):
    self.rev_index = {}
    self.urls_index = {}
    self.snippets = {}
    for w in self.init_index_vals:
      self.rev_index[self.stemmer.stem(w)] = {"term":w, "DocIDs": [], "DocIDs_cntrs": []}


  def get_snippet(self, url):
    return self.snippets[url] if url in self.snippets else "No snippet"

"""# Crawler Service"""

class CrawlerService:

  def __init__(self, indexService, baseURLs=set(['https://www.ibm.com/us-en', 'https://www.ibm.com/topics']) ,maxDepth=100):
    self.indexService = indexService
    self.maxDepth = maxDepth
    self.resetService()
    self.baseURLs = baseURLs

  def initCrawlingProcess(self, max_depth=10):
    self.resetService()
    for url in self.baseURLs:
      self.crawl_website(url, max_depth)

    # Function to crawl a website and fetch n pages
  def crawl_website(self, base_url, max_pages=100):
      rp = self.__check_robot(base_url)  # Check the robots.txt file
      urls_to_crawl = [base_url]  # Initialize the queue with the base URL
      current_crawled_urls = set()
      ignore_urls = ["form", "mp3", "mp4", "downloads", "zip"]

      while urls_to_crawl and len(current_crawled_urls) < max_pages:
          current_url = urls_to_crawl.pop(0)

          if current_url in self.crawled_urls:
              continue  # Skip already crawled URLs

          print(f"Crawling {self.crawled_count+1}: {current_url}")
          try:
            page_content = self.__fetch_page_crawler(current_url, rp)
          except:
            print("Failed to crawl with robot, trying without")
            page_content = self.__fetch_page_crawler(current_url)

          if page_content:
              self.crawled_urls.add(current_url)
              current_crawled_urls.add(current_url)
              self.crawled_count += 1

              # Extract and queue new links to crawl
              new_links = self.__extract_links(page_content, base_url)
              for link in new_links:
                  cond1 = any(bad_url in link for bad_url in ignore_urls)
                  cond2 = any(u for u in self.crawled_urls if (f"{u}#" in link))
                  cond = cond1 or cond2
                  if link not in self.crawled_urls and link not in urls_to_crawl and not cond:
                      urls_to_crawl.append(link)

              soup = BeautifulSoup(page_content, 'html.parser')
              self.indexService.process_soup(current_url, soup)
              # Delay between requests to avoid overwhelming the server
              time.sleep(2)  # Sleep for 2 seconds between requests (politeness)

      print(f"\nCrawled {len(current_crawled_urls)} pages.")
      return current_crawled_urls

  def crawl_single_url(self, url):
      if url in self.crawled_urls:
        return "Url was already crawled"
      # rp = self.__check_robot(url)  # Check the robots.txt file
      print(f"Crawling {self.crawled_count+1}: {url}")
      page_content = self.__fetch_page_crawler(url)

      if page_content:
        self.crawled_urls.add(url)
        self.crawled_count += 1

        soup = BeautifulSoup(page_content, 'html.parser')
        self.indexService.process_soup(url, soup)
        time.sleep(2)  # Sleep for 2 seconds between requests (politeness)
        self.baseURLs.add(url)
        return "Url was crawled successfully"
      else:
        return "Cannot crawl given url"



  def get_crawled_urls(self):
    return self.crawled_urls

  def resetService(self):
    self.crawled_urls = set()
    self.crawled_count = 0
    self.robot = None

  # Function to fetch and parse the robots.txt file to check permissions
  def __check_robot(self, url):
      # print(f"__check_robot url='{url}'")
      robot_url = urljoin(url, '/robots.txt')
      rp = RobotFileParser()
      rp.set_url(robot_url)
      # Fetch and parse robots.txt file
      rp.read()
      if rp:
        self.robot = rp
      return rp if rp else self.robot

  # Function to fetch and parse a page
  def __fetch_page_crawler(self, url, rp=None):
      # Check if the URL is allowed to be crawled according to robots.txt
      if rp and not rp.can_fetch('*', url):  # '*' means all user agents
          print(f"Blocked by robots.txt: {url}")
          return None

      try:
          response = requests.get(url, timeout=5)
          response.raise_for_status()  # Will raise an exception for 4xx or 5xx responses
          return response.text
      except requests.exceptions.RequestException as e:
          print(f"Error fetching {url}: {e}")
          return None

  # Function to extract internal links from a page
  def __extract_links(self, page_content, base_url):
      soup = BeautifulSoup(page_content, 'html.parser')
      links = set()

      # Find all anchor tags and extract the href attribute
      # TODO need to add all links that are in tags with property cta-type="local
      for anchor in soup.find_all('a', href=True):
          href = anchor['href']

          # Resolve relative URLs to absolute URLs
          full_url = urljoin(base_url, href)

          # Only add links that are within the same domain (ibm.com)
          if urlparse(full_url).netloc == urlparse(base_url).netloc:
              links.add(full_url)
      for tag in soup.find_all(attrs={'cta-type': 'local'}, href=True):
        href = tag['href']
        # Resolve relative URLs to absolute URLs
        full_url = urljoin(base_url, href)

        # Only add links that are within the same domain
        if urlparse(full_url).netloc == urlparse(base_url).netloc:
            links.add(full_url)

      return links

"""# Query Service"""

class QueryService:

  # enable boolean search

  def __init__(self, indexService):
    self.indexService = indexService
    # self.query_history_results = {}   # query => urls
    self.query_history = []   # query => urls

  def query(self, query):
    res=self.__query_process(query)
    self.query_history.insert(0, {'query': query, 'results': res})
    return res

  def get_history(self):
    return self.query_history

  def __query_process(self, query):
    if "and" in query:
      ind=query.find("and")
      return self.__andResults(self.__query_process(query[:ind]), self.__query_process(query[ind+3:]))
    elif "or" in query:
      ind=query.find("or")
      return self.__orResults(self.__query_process(query[:ind]), self.__query_process(query[ind+2:]))
    return self.__queryByString(query)

  def __queryByString(self, query):
    url_res_set = set()
    query_words = set(re.findall(r'\w+', query.lower()))
    stemmer = PorterStemmer()
    stemmed_query = set()
    rev_index = self.indexService.get_reverse_index()

    for word in query_words:
        stemmed_word = stemmer.stem(word)
        stemmed_query.add(stemmed_word)
        # Add URLs to the result set if stemmed_word exists in reverse index
        if stemmed_word in rev_index:
            url_res_set.update(rev_index[stemmed_word]["DocIDs"])

    ranked_url_res = []
    for url_val in url_res_set:
      snippet = self.indexService.get_snippet(url_val)

      ranked_url_res.append({
        'url': url_val,
        'rank': self.rank_url(url_val, stemmed_query),
        'snippet': snippet
      })

    # Sort the result by rank in descending order
    ranked_url_res = sorted(ranked_url_res, key=lambda item: item['rank'], reverse=True)
    return ranked_url_res

  def __andResults(self, lst1, lst2):
    res_dict = {item['url']: item['rank'] for item in lst2}
    intersection = []
    for item in lst1:
        url = item['url']
        if url in res_dict:
            new_rank = (item['rank'] + res_dict[url])/2
            snippet = self.get_snippet(url)
            intersection.append({'url': url, 'rank': new_rank, 'snippet': snippet})

    # Sort the result by rank in descending order
    return sorted(intersection, key=lambda item: item['rank'], reverse=True)

  def __orResults(self, lst1, lst2):
    combined_dict = {}

    for item in lst1:
      url = item['url']
      rank = item['rank']
      snippet = item['snippet']
      combined_dict[url] = {'rank': max(combined_dict.get(url, {'rank': float('-inf')})['rank'], rank), 'snippet': snippet}

    for item in lst2:
      url = item['url']
      rank = item['rank']
      snippet = item['snippet']
      if url in combined_dict:
        combined_dict[url]['rank'] = max(combined_dict[url]['rank'], rank)
      else:
        combined_dict[url] = {'rank': rank, 'snippet': snippet}

    return sorted(
      [{'url': url, 'rank': data['rank'], 'snippet': data['snippet']} for url, data in combined_dict.items()],
      key=lambda item: item['rank'],
      reverse=True)

  def rank_url(self, url, query_words):
    rank = 1
    # resultService = ResultService()
    # rank based on lab6
    url_index = self.indexService.get_url_index(url)
    for word in query_words:
      if word in url_index:
        rank = rank*1/url_index[word]
    rank = 1-rank
    # print(rank)
    return rank

"""# Graph Service"""

class GraphService:
    def __init__(self, indexService, heatmap_output, bar_output, max_heatmap_items = 15, max_bar_items = 15):
        """
        Initializes the GraphService with the reverse index data.
        """
        self.indexService = indexService
        self.index_df_coalition_heatmap = None
        self.index_df_urls_heatmap = None
        self.index_df_bar = None
        self.max_heatmap_items = max_heatmap_items
        self.max_bar_items = max_bar_items
        self.heatmap_output, self.bar_output = heatmap_output, bar_output
        self.buildDFs()

    def buildDFs(self):
        """
        Builds the dataframes for heatmap and bar chart from the reverse index data,
        with filtering applied to limit the data to terms with sufficient occurrences or shared documents.
        """
        rev_index = self.indexService.get_reverse_index()

        # Build the heatmap data
        self.index_df_coalition_heatmap = self.__get_shared_docs_dataframe(rev_index)

        # Collect data for the heatmap
        webpage_data = defaultdict(lambda: {"words": [], "occurrences": []})
        for key, value in rev_index.items():
            doc_ids = value.get("DocIDs", [])
            doc_ids_cntrs = value.get("DocIDs_cntrs", [])
            term = value.get("term", "")

            for doc_id, count in zip(doc_ids, doc_ids_cntrs):
                webpage_data[doc_id]["words"].append(term)
                webpage_data[doc_id]["occurrences"].append(count)

        # Create DataFrame for heatmap
        webpage_dataframes = {}
        for page, content in webpage_data.items():
            webpage_df = pd.DataFrame({
                "words": content["words"],
                "occurrences": content["occurrences"]
            })
            webpage_dataframes[page] = webpage_df

        self.index_df_urls_heatmap = pd.DataFrame({
            page: {row["words"]: row["occurrences"] for _, row in df.iterrows()}
            for page, df in webpage_dataframes.items()
        }).fillna(0)

        # Create DataFrame for bar chart
        word_totals = self.index_df_urls_heatmap.sum(axis=1).reset_index()
        word_totals.columns = ["word", "occurrences"]

        self.index_df_bar = word_totals

        # Build the visualizations
        self.build_heatmap()
        self.build_barChart()



    def build_heatmap(self):
      """
      Returns the heatmap graph wrapped in a widget output,
      displaying only the lower triangle (without diagonal or upper triangle),
      and keeping the original matrix size.
      """
      with self.heatmap_output:
          self.heatmap_output.clear_output()
          print("Heatmap: Shared URLs between Indexes")
          print("The value at each cell [i,j] is the amount of shared urls between index i and index j")
          print(f"# The graph only displays top {self.max_heatmap_items} indexes with the most shared URLs with other indexes")

          # Retrieve the matrix with only the lower triangle
          df = self.index_df_coalition_heatmap

          plt.figure(figsize=(13, 10))  # Increased size of the figure

          # Display heatmap with lower triangle masked
          mask = np.triu(np.ones(df.shape, dtype=bool), k=1)  # Create a boolean upper triangle mask

          # Then, pass the mask to sns.heatmap
          sns.heatmap(
              df,
              annot=True,
              cmap="YlGnBu",
              linewidths=0.5,
              fmt="g",
              cbar_kws={'label': 'Occurrences'},
              square=True,  # Ensure that it's square
              annot_kws={'size': 10},  # Adjust annotation text size
              mask=mask,  # Use the boolean mask directly
              cbar=True,  # Show colorbar
          )


          # Set title and labels for the plot
          plt.title("Heatmap: Shared URLs between Indexes", fontsize=14)
          plt.xlabel("Index 1", fontsize=12)
          plt.ylabel("Index 2", fontsize=12)
          plt.xticks(rotation=45, ha='right')
          plt.tight_layout()  # Ensure labels don't overlap

          plt.show()

      return self.heatmap_output


    def build_barChart(self):
        """
        Returns the bar chart graph wrapped in a widget output, limiting to top self.max_bar_items words.
        """
        with self.bar_output:
            self.bar_output.clear_output()
            print(f"Bar Chart: Word Occurrences Across IBM (Top {self.max_bar_items} Words)")

            # Limit to top self.max_bar_items terms by occurrences
            sorted_df = self.index_df_bar.sort_values(by="occurrences", ascending=False).head(self.max_bar_items)

            plt.figure(figsize=(14, 8))
            sns.barplot(data=sorted_df, x="word", y="occurrences", hue="word", palette="viridis", legend=False)
            plt.title("Bar Chart: Word Occurrences Across IBM", fontsize=16)
            plt.xlabel("Words", fontsize=14)
            plt.ylabel("Occurrences", fontsize=14)
            plt.xticks(rotation=45, fontsize=10)
            plt.tight_layout()
            plt.show()
        return self.bar_output


    def __get_shared_docs_dataframe(self, reverse_index):
        """
        Creates a DataFrame for shared documents between terms.
        Keeps only the top self.max_heatmap_items terms with the most shared document occurrences.
        """
        count_shared_docs = lambda docs1, docs2: len(set(docs1) & set(docs2))

        # Getting the list of indices (terms)
        indices = list(reverse_index.keys())

        # Calculate total shared docs per term
        shared_doc_counts = {
            term: sum(len(set(reverse_index[term]["DocIDs"]) & set(reverse_index[other]["DocIDs"]))
                      for other in indices)
            for term in indices
        }

        # Keep the top self.max_heatmap_items terms based on shared docs
        top_terms = sorted(shared_doc_counts, key=shared_doc_counts.get, reverse=True)[:self.max_heatmap_items]

        data = {}
        for index1 in top_terms:
            data[reverse_index[index1]["term"]] = {}
            for index2 in top_terms:
                shared_docs_count = count_shared_docs(
                    reverse_index[index1]["DocIDs"], reverse_index[index2]["DocIDs"]
                )
                data[reverse_index[index1]["term"]][reverse_index[index2]["term"]] = shared_docs_count

        df = pd.DataFrame(data)
        return df

"""# SearchEngineUI"""

class SearchEngineUI:
    def __init__(self, queryService, history_service):
        """
        Initializes the SearchEngineUI with the queryService and history_service.
        """
        desc = widgets.Output()
        with desc:
          print("To query please enter text into the field and press the 'Search' button")
          print("Each page in the result is ranked by the amount the query's keywords appear in the page's text")
          print("Search for terms learned in class (IBM, AI, SAAS, etc...)")
          print("There is support for AND and OR operators")
          print()
        self.queryService = queryService
        self.history_service = history_service  # Link to the history service
        self.query_input = widgets.Text(
            placeholder="Enter your search query here...",
            description="Query:",
            layout=widgets.Layout(width='70%')
        )
        self.search_button = widgets.Button(
            description="Search",
            button_style="primary",
            tooltip="Click to search",
            icon="search",
            layout=widgets.Layout(border_radius="20px", width="70px", height="25px"),
            disabled=True
        )
        self.results_output = widgets.Output()
        self.pagination_controls = widgets.HBox([])  # Placeholder for pagination controls
        self.result_count_label = widgets.Label(value="")  # Label for displaying result count

        self.current_query = None
        self.current_results = []
        self.current_page = 0

        # Attach event handlers
        # self.query_input.on_submit(self.perform_search)
        self.query_input.observe(self.__on_text_change, names='value')
        self.search_button.on_click(self.__perform_search)

        # Layout the GUI
        self.gui = widgets.VBox([
            desc,
            widgets.HBox([self.query_input, self.search_button]),
            self.result_count_label,  # Add the result count label
            self.results_output,
            self.pagination_controls
        ])

    def display(self):
        """
        Displays the GUI for the SearchEngineUI.
        """
        display(self.gui)

    def query(self, query_str):
        """Executes a query and returns the results."""
        try:
            results = self.queryService.query(query_str)
            return results
        except Exception as e:
            print(f"An error occurred during the query: {e}")
            return []

    def __on_text_change(self, change):
        # Disable the button if text is being typed
        if change.new:
            self.search_button.disabled = False
        else:
            self.search_button.disabled = True

    def __perform_search(self, change):
        """
        Executes the search and displays the first page of results.
        """
        query = self.query_input.value.strip()
        if not query:
            with self.results_output:
                self.results_output.clear_output()
                print("Please enter a search query.")
            return

        startTime = time.time()
        # Execute the query and save the results
        self.current_query = query
        self.current_results = self.query(query.lower())
        self.current_page = 0

        # Save the query and results in history service
        # if self.current_results:
        self.history_service.save_search(query, self.current_results)

        # Update the result count label
        endTime = time.time()
        self.update_result_count(len(self.current_results), endTime-startTime)

        # Display the first page of results
        self.display_page(self.current_page)

    def update_result_count(self, count, time_took):
        """
        Updates the label displaying the number of results received.
        """
        self.result_count_label.value = f"Number of results: {count} (took {time_took:.3f} sec)"

    def display_page(self, page):
        """
        Displays a specific page of results.
        """
        with self.results_output:
            self.results_output.clear_output()
            start = page * 10
            end = start + 10
            chunk = self.current_results[start:end]

            if not chunk:
                print("No results to display.")
                self.update_pagination_controls()
                return

            # Convert results to a DataFrame and display clickable links
            results_df = pd.DataFrame(chunk)
            if 'url' in results_df.columns:
                results_df = results_df[['url']]
                results_df['url'] = results_df['url'].apply(
                    lambda x: f'<a href="{x}" target="_blank">{x}</a>'
                )
                numbered_results = []
                for i, url in enumerate(results_df['url']):
                  rank_of_url = (self.current_results[start+i]['rank'])*100
                  if rank_of_url < 0.01:
                    rank_of_url = 0.01
                  numbered_results.append(
                    f'<div style="background-color: {"#f9f9f9" if i % 2 == 0 else "#eaeaea"}; padding: 8px;">'
                    f"{i + 1 + start}. {url} (match: {rank_of_url:.2f}%)<br>"
                    f"<span style='color: gray;'>{(self.current_results[start + i].get('snippet', 'No snippet available'))}...</span>"
                    f"</div>"
                  )

                html = '<div style="text-align: left; font-family: Arial; font-size: 14px;">' + ''.join(
                    numbered_results
                ) + '</div>'
                display(HTML(html))

        # Update pagination controls
        self.update_pagination_controls(page)

    def update_pagination_controls(self, page=None):
        """
        Updates the pagination controls based on the current page.
        """
        if page == None:
          self.pagination_controls.children = []
          return

        total_pages = (len(self.current_results)) // 10 + (len(self.current_results) % 10 !=0)  # Calculate total pages

        # Create Previous and Next buttons
        prev_button = widgets.Button(
            description="Previous",
            icon="arrow-left",
            button_style="info",
            disabled=(page == 0),  # Disable if on the first page
            layout=widgets.Layout(
                border_radius="20px",  # Rounder corners
                width="70px",  # Smaller button width
                height="25px"  # Smaller button height
            )
        )
        next_button = widgets.Button(
            description="Next",
            icon="arrow-right",
            button_style="info",
            disabled=(page == total_pages - 1) , # Disable if on the last page
            layout=widgets.Layout(
                border_radius="20px",  # Rounder corners
                width="70px",  # Smaller button width
                height="25px"  # Smaller button height
            )
        )
        # Attach event handlers
        prev_button.on_click(lambda b: self.display_page(page - 1))
        next_button.on_click(lambda b: self.display_page(page + 1))
        prev_button.layout.display = ("flex" if page != 0 else "none")
        next_button.layout.display = ("flex" if page != total_pages - 1 else "none")

        label=widgets.Label(f"Page {page + 1} of {total_pages}")

        # Update the pagination controls layout
        self.pagination_controls.children = [prev_button, label, next_button] if total_pages else []

"""# SearchHistoryUI"""

#משימה ששלומי נתן לישראל 31.12.24
#בוצעה

class SearchHistoryUI:
    def __init__(self):
        """
        Initializes the SearchHistoryUI.
        """
        self.infoText = "Here you can view the last five queries you've made, and the top ten results for each.\n"
        self.infoText += "They are ordered as such: 1 - the latest query, 5 - the oldest query.\n"
        self.infoText += "Click on the row to view the query's result.\n\n"
        self.history = []  # List to store search history
        self.history_output = widgets.Output()  # Output widget for displaying history
        with self.history_output:
          print("You have no history.")

    def save_search(self, query, results):
        """
        Saves the search query and its results to the history.
        """
        self.history.append({"query": query, "results": results})
        self.history = self.history[-5:]  # Keep only the last 5 searches
        self.display_history()  # Update the history display

    def display_history(self):
        """
        Displays the 5 most recent search results in the History Service tab with numbering and result counts.
        """
        with self.history_output:
            self.history_output.clear_output()
            print(self.infoText)

            if not self.history:
                print("No recent searches available.")
            else:
                accordion = widgets.Accordion()  # Create an accordion for collapsible lists
                for i, entry in enumerate(reversed(self.history), start=1):  # Most recent first
                    # Create HTML for the list of URLs
                    results_html = "<ul>"
                    for site_index, result in enumerate(entry["results"][:10], start=1):
                        results_html += f'<li>{site_index}. <a href="{result["url"]}" target="_blank">{result["url"]}</a></li>'
                    results_html += "</ul>"

                    # Create an output widget to hold the list of URLs
                    result_output = widgets.Output()
                    with result_output:
                        display(HTML(results_html))

                    # Add the query with result count as a button with collapsible functionality
                    result_count = len(entry["results"])
                    accordion.children += (result_output,)
                    # accordion.set_title(i - 1, f"{i}. Query: {entry['query']} (Results: {result_count})")
                    accordion.set_title(i - 1, f"Query No.{i}: {entry['query']} {'(no results)' if not len(entry['results']) else ''}")

                # Display the accordion
                display(accordion)

    def get_output_widget(self):
        """
        Returns the output widget for the History Service tab.
        """
        return self.history_output

"""# ChatbotUI"""

class ChatbotUI:

  def __init__(self, indexService):
    genai.configure(api_key='AIzaSyDzCZQbp6pnPuHE0bzRP37-KP9UVNyC6sY')
    self.model = genai.GenerativeModel('gemini-1.5-flash')
    self.indexService = indexService
    # self.__initBot()
    self.__buildGUI()
    pass

  def display(self):
    display(self.gui)

  def __buildGUI(self):

        desc = widgets.Output()
        with desc:
          print("To talk with the chatbot enter text into the field and press the 'Send' button")
          print()
        self.msg_input = widgets.Text(
            placeholder="Enter your message here (I only know terms)",
            description="Message:",
            layout=widgets.Layout(width='70%')
        )
        self.send_button = widgets.Button(
            description="Send",
            button_style="primary",
            tooltip="Click to search",
            icon="send",
            layout=widgets.Layout(border_radius="20px", width="70px", height="25px")

        )
        self.results_output = widgets.Output()

        # Attach event handler
        self.msg_input.on_submit(self.__perform_send)
        self.send_button.on_click(self.__perform_send)

        # Layout the GUI
        self.gui = widgets.VBox([
            desc,
            widgets.HBox([self.msg_input, self.send_button]),
            self.results_output
        ])

  def __perform_send(self, q):
        msg = self.msg_input.value.strip()
        if not msg:
            with self.results_output:
                self.results_output.clear_output()
                print("Please enter a message.")
            return

        # Display results
        with self.results_output:
            self.results_output.clear_output()
            print("Thinking...")
            # Get the results for the message
            # results = self.chatbot.respond(msg) if self.__termInMessage(msg) else "404"
            results = self.__getAI_response(msg)
            self.results_output.clear_output()
            if not results:
                print("No results found for your term.")
            else:
                # Assuming the response is a list of strings
                if isinstance(results, list):
                    response_text = "\n".join(results)
                else:
                    response_text = str(results)  # Convert to string if not already
                display(widgets.HTML(f"<b>Response:</b> {response_text}"))

  def __getAI_response(self, query):
    msg = "I will give you a message, act as a chatbot related to IBM (with only info from the IBM website)"
    msg += ", I want you to give an answer that is a summery, with max 10 lines"
    msg += f". Message (any text after this is the message): {query}"
    try:
      response = self.model.generate_content(msg)
      return response.text
    except err:
      return "Sorry, I didn't understand (Genai is tired)"

  def __termInMessage(self, msg):
    words = re.findall(r'\b\w+\b', msg)  # Find individual words
    for word in words:
        if word.lower() in self.term_summaries:
            return True
    return False

"""# EditIndexUI"""

class EditIndexUI:

  def __init__(self, indexService, crawlerService, graphService):
    self.indexService = indexService
    self.crawlerService = crawlerService
    self.opFunc = {
        "1": self.__printAction,
        "2": self.__addWordAction,
        "3": self.__removeWordAction,
        "4": self.__addURLAction,
        "5": self.__removeURLAction,
        "6": self.__saveAction,
        "7": self.__loadAction,
        "8": self.__crawlAction,
        # "9": self.__exitAction,
    }
    self.opInputPrompt = {
        "2": "Please enter the word to be added: ",
        "3": "Please enter a word to be removed: ",
        "4": "Please enter a url to be added: ",
        "5": "Please enter a url to be removed: ",
        "8": "Please enter the max depth for each crawling: ",
    }
    self.selectFunc = None
    self.graphService = graphService

  def display(self):
      self.menu_output = widgets.Output()
      with self.menu_output:
          print("To select an option, enter the option's number in the field below.")
          print("If there is a need for further input you will be prompt to enter it in the second field.")
          print()
          print("\nIndex Edit Menu:")
          print("\t1. Print index")
          print("\t2. Add a new word to index")
          print("\t3. Remove word from index")
          print("\t4. Add a new url to crawl")
          print("\t5. Remove a url")
          print("\t6. Save to FireBase")
          print("\t7. Load from FireBase")
          print("\t8. Start crawling")
          # op=input("Choose an option [1-8]: ")

      self.msg_input = widgets.Text(
          placeholder="[1-8]",
          description="Choose an option [1-8]: :",
          style={'description_width': "auto"},
          layout=widgets.Layout(width='40%')
      )
      self.send_button = widgets.Button(
          description="Send",
          button_style="primary",
          tooltip="Click to search",
          style={'description_width': "auto"},
          icon="send",
          layout=widgets.Layout(border_radius="20px", width="70px", height="30px")
      )

      self.data_input = widgets.Text(
          placeholder="Enter input",
          style={'description_width': "auto"},
          layout=widgets.Layout(width='50%', display='none')
      )
      self.data_button = widgets.Button(
          description="Submit",
          button_style="primary",
          tooltip="Click to search",
          style={'description_width': "auto"},
          layout=widgets.Layout(display='none'),
          icon="send"
      )

      self.results_output = widgets.Output()

      # Attach event handler
      self.msg_input.on_submit(self.__perform_action)
      self.send_button.on_click(self.__perform_action)
      self.data_input.on_submit(self.__doActionOnClick)
      self.data_button.on_click(self.__doActionOnClick)

      self.gui = widgets.VBox([
          self.menu_output,
          widgets.HBox([self.msg_input, self.send_button]),
          widgets.HBox([self.data_input, self.data_button]),
          self.results_output
      ])
      display(self.gui)

  def __perform_action(self, o):

    self.op = self.msg_input.value.strip()
    self.results_output.clear_output()
    with self.results_output:

        self.selectFunc = self.opFunc.get(self.op,None)
        if self.selectFunc == None:
          print("Invalid action")
        else:
          self.data_input.value=""
          if (self.op in self.opInputPrompt):
            self.data_input.description = self.opInputPrompt.get(self.op, "ERROR")
            self.data_input.value=""
            self.data_input.layout.display = "flex"
            self.data_button.layout.display = "flex"
          else:
            self.data_input.layout.display = "none"
            self.data_button.layout.display = "none"
            self.__toggleDisabled()
            self.selectFunc()
            self.__toggleDisabled()

  def __toggleDisabled(self):
    flag = not self.msg_input.disabled
    self.msg_input.disabled = flag
    self.send_button.disabled = flag
    self.data_input.disabled = flag
    self.data_button.disabled = flag


  def __doActionOnClick(self, q):
    with self.results_output:
      if self.selectFunc:
        self.__toggleDisabled()
        if self.selectFunc() != -1:
          print("Starting to update the graphs")
          self.graphService.buildDFs()
          print("The graphs got updated")
        self.__toggleDisabled()
      else:
        print("Invalid action")
    self.data_input.layout.display = "none"
    self.data_button.layout.display = "none"

  def __printAction(self):
    print(self.indexService.index_toString())

  def __addWordAction(self):
    w = self.data_input.value.strip()

    if self.indexService.add_new_word(w):
      print(f"New word added '{w}': {self.indexService.get_index_of_word(w)}")
      print("A crawl is needed to build its index")
    else:
      print("The word was already in index")
      return -1

  def __removeWordAction(self):
    w = self.data_input.value.strip()

    if self.indexService.remove_word(w):
      print(f"The word '{w}' was removed from index")
    else:
      print(f"The word '{w}' wasn't in the index")
      return -1

  def __addURLAction(self):
    u = self.data_input.value.strip()
    with self.results_output:
      if not u: #Check if empty
        print("Empty url")
      else:
        msg = self.crawlerService.crawl_single_url(u)
        print("Crawling result:", msg)

  def __removeURLAction(self):
    u = self.data_input.value.strip()

    with self.results_output:
      if self.indexService.remove_url(u):
        print("Url removed from index")
      else:
        print("Url was not in index")
        return -1


  def __saveAction(self):
    self.indexService.save_in_db()

  def __loadAction(self):
    self.indexService.load_from_db()
    print("index loaded from db")

  def __crawlAction(self):
    try:
      num = int(self.data_input.value.strip())
    except:
      print("Not an integer")
      return -1
    try:
      self.crawlerService.initCrawlingProcess(num)
    except Exception as err:
      print(f"Crawling failed: {err}")
      return -1

"""# InitUI functions"""

#משימה ששלומי נתן לישראל 31.12.24
#בוצעה

def display_tabs(search_ui, history_service, graphService, chatbot_ui, editIndexUI):
    """
    Creates and displays the tabs containing the search engine, history, and other features.
    """
    # Create a container for the search engine UI in the first tab
    query_service_output = widgets.Output()
    with query_service_output:
        search_ui.display()
    query_service_output.layout = widgets.Layout()
    query_service_output.add_class("search-ui-container")  # Add custom class for search_ui

    # Get the output widget for the history service
    history_service_output = history_service.get_output_widget()
    history_service_output.add_class("history-ui-container")  # Add custom class for history_service

    # Create a container for the Chatbot UI
    chatbot_service_output = widgets.Output()
    with chatbot_service_output:
        chatbot_ui.display()
    chatbot_service_output.add_class("chatbot-ui-container")  # Add custom class for chatbot_ui

    # Create a container for the Edit Index Menu
    index_menu_output = widgets.Output()
    with index_menu_output:
        editIndexUI.display()
    index_menu_output.add_class("edit-index-ui-container")  # Add custom class for editIndexUI

    # Create containers for graphService outputs
    heatmap_output_container = widgets.Output()
    with heatmap_output_container:
        display(graphService.heatmap_output)
    heatmap_output_container.add_class("graph-ui-container")

    bar_output_container = widgets.Output()
    with bar_output_container:
        display(graphService.bar_output)
    bar_output_container.add_class("graph-ui-container")

    # Create the tabs
    tabs_toDisplay = [
        {"Search Engine": query_service_output},
        {"History": history_service_output},
        {"Chatbot": chatbot_service_output},
        {"Index Coalitions": heatmap_output_container},
        {"Index Occurrences": bar_output_container},
        {"Index Menu": index_menu_output},
    ]
    tabs = widgets.Tab(children=tuple(value for tab in tabs_toDisplay for value in tab.values()))
    for i, k in enumerate([key for tab in tabs_toDisplay for key in tab.keys()]):
        tabs.set_title(i, k)

    # Inject custom CSS for the tabs and their content areas
    custom_css = """
    <style>
        /* Style for the tab buttons */
        .p-TabBar-tab {
            background-color: #F9F9F9 !important; /* Light blue background */
            border-radius: 10px;
            margin: 2px;
            padding: 5px;
        }
        .p-TabBar-tab.p-mod-active {
            background-color: #f0f0f0 !important; /* Slightly darker blue for active tab */
        }
        .p-TabBar-tab:hover {
            background-color: #E6EBFF !important; /* Lighter blue for hover effect */
        }

        /* Style for the tab content areas */
        .widget-tab-contents {
            background-color: #f0f0f0; /* Very light blue background for content */
            padding: 15px;
            border-radius: 10px;
        }



        /* Style for the search bar */
          input[type="text"] {
              border-radius: 20px !important;
              padding: 8px;
              border: 1px solid #ccc;
              width: 90%;
          }

          /* Style for buttons */
          .widget-button {
              border-radius: 20px !important; /* Rounder corners */
              font-size: 12px; /* Adjust font size for smaller button */
              font-weight: bold;
              text-align: center;
              display: flex; /* Use flexbox */
              align-items: center; /* Vertically center text */
              justify-content: center; /* Horizontally center text */
          }

          /* Optional: Add hover effects */
          .widget-button:hover {
              background-color: #A1A1A1 !important;
          }




        /* Custom style for search_ui container */
        .search-ui-container {
            background-color: #f9f9ff; /* Very very light gray background */
            padding: 20px;
            border-radius: 10px;
        }

        /* Custom style for history_service container */
        .history-ui-container {
            background-color: #f9f9ff; /* Very light gray background */
            padding: 20px;
            border-radius: 10px;
        }

        /* Custom style for chatbot_ui container */
        .chatbot-ui-container {
            background-color: #f9f9ff; /* Very light blue background */
            padding: 20px;
            border-radius: 10px;
        }

        /* Custom style for editIndexUI container */
        .edit-index-ui-container {
            background-color: #f9f9ff; /* Neutral gray background */
            padding: 20px;
            border-radius: 10px;
        }

        /* Custom style for graphService containers */
        .graph-ui-container {
            background-color: #f9f9ff; /* Very light purple background */
            padding: 20px;
            border-radius: 10px;
        }
    </style>
    """

    display(HTML(custom_css))

    # Display the tabs
    display(tabs)

def initGUIProcess(indexService, editIndexUI, graphService):
  queryService = QueryService(indexService)
  # Assuming GraphService and indexService are already defined

  # Define the history service output
  history_output = SearchHistoryUI()

  # Assuming SearchEngineUI and queryService are already defined
  search_ui = SearchEngineUI(queryService,history_output)
  chatbot_ui = ChatbotUI(indexService)

  # SVG URL
  phoenix_svg_url = "https://raw.githubusercontent.com/ShlomiFridman/PhoenixProject2025/42847053ee0f661c5f25bc0d06ea7daf740e3cde/Project/phoenix-svgrepo-com.svg"
  ibm_svg_url = "https://raw.githubusercontent.com/ShlomiFridman/PhoenixProject2025/e11c8ccf8c7ffe08da02f4df74393f6472f5bf51/Project/IBM_logo.svg"

    # Embed SVG with resizing
  svg_resized_html = f'''
  <div style="display: flex; align-items: center;">
      &emsp;<div style="width: 100px; height: 100px;">
          <img src="{ibm_svg_url}" style="width: 100%; height: 100%;" />
      </div>
      &emsp;
      <div style="width: 100px; height: 100px;">
          <img src="{phoenix_svg_url}" style="width: 100%; height: 100%;" />
      </div>
      <div style="margin-left: 10px; font-size: 20px; font-weight: bold;">
          Phoenix 2025 Search Engine
      </div>
  </div>
  '''

  # Gradient background styling
  style_block = '''
  <style>
      body {
        margin: 0; /* Remove default margin */
        padding: 0; /* Remove default padding */
        height: 100vh; /* Make the body span the full viewport height */
        background: linear-gradient(to bottom right, lightblue, orange);
        background-repeat: no-repeat; /* Prevent gradient from repeating */
        background-attachment: fixed; /* Keep background fixed during scrolling */
      }
  </style>
  '''

  # Display everything
  full_html = f"{style_block}{svg_resized_html}"
  display(HTML(full_html))

  # Display the tabs with the search engine and other services
  display_tabs(search_ui, history_output, graphService, chatbot_ui, editIndexUI)

"""# main"""

def mainProcess():
  firebaseService = FirebaseService()
  indexService = IndexService(firebaseService=firebaseService)
  indexService.load_from_db()
  crawlerService = CrawlerService(indexService, maxDepth=10)
  graphService = GraphService(indexService, widgets.Output(), widgets.Output())
  editIndexUI = EditIndexUI(indexService, crawlerService, graphService)
  initGUIProcess(indexService, editIndexUI, graphService)

mainProcess()